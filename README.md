# åŸºäº CNN ä¸ LSTM çš„ç»“æ„åŒ–å­—ç¬¦è¯†åˆ«ä¸é¢„æµ‹å»ºæ¨¡

æœ¬é¡¹ç›®ä¸º UNSW Neural Networks è¯¾ç¨‹ COMP9444 çš„è¯¾ç¨‹ä½œä¸šï¼Œæ¶µç›–å›¾åƒåˆ†ç±»ã€å‰é¦ˆç¥ç»ç½‘ç»œå¯è§†åŒ–ã€åºåˆ—ç»“æ„å»ºæ¨¡ä¸ LSTM åµŒå¥—è¯­æ³•å­¦ä¹ ã€‚é¡¹ç›®å…±åˆ†ä¸ºä¸‰å¤§éƒ¨åˆ†ï¼Œé€šè¿‡ PyTorch å®ç°å¤šä¸ªç½‘ç»œç»“æ„ï¼Œç»“åˆå¯è§†åŒ–åˆ†æç†è§£æ¨¡å‹çš„å†…éƒ¨åŠ¨æ€è¿‡ç¨‹ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„

â”œâ”€â”€ NetLin / NetFull / NetConv # å›¾åƒåˆ†ç±»ç½‘ç»œæ¨¡å‹ï¼ˆKMNIST æ•°æ®é›†ï¼‰
â”œâ”€â”€ check.py / check_main.py # MLP æ‰‹åŠ¨è®¾æƒè®­ç»ƒä¸æ¿€æ´»å›¾å¯è§†åŒ–
â”œâ”€â”€ anbn.py # anbn åºåˆ—æ•°æ®ç”Ÿæˆå™¨
â”œâ”€â”€ RNN + LSTM + å¯è§†åŒ–è¾“å‡º # åºåˆ—ç»“æ„å­¦ä¹ ä¸å¯è§£é‡Šæ€§åˆ†æ
â”œâ”€â”€ plot/ # ä¿å­˜å¯è§†åŒ–ç»“æœï¼ˆæ¿€æ´»å›¾ã€è¾“å‡ºå›¾ã€è½¨è¿¹å›¾ç­‰ï¼‰
â”œâ”€â”€ hw1.pdf # æœ€ç»ˆæŠ¥å‘ŠåŠå®éªŒæ€»ç»“
---

## ğŸ§  é¡¹ç›®åŠŸèƒ½ä¸æˆæœæ¦‚è§ˆ

### 1. å›¾åƒåˆ†ç±»ï¼ˆKMNISTï¼‰

- ä½¿ç”¨ä¸‰ç§ç»“æ„ï¼šçº¿æ€§æ¨¡å‹ï¼ˆNetLinï¼‰ã€MLPï¼ˆNetFullï¼‰ã€CNNï¼ˆNetConvï¼‰
- å‡†ç¡®ç‡åˆ†åˆ«ä¸º **70% / 85% / 94%**
- å®ç° PyTorch è‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒä¸æµ‹è¯•æ¡†æ¶

### 2. MLP å¯è§†åŒ–ä¸é€»è¾‘å»ºæ¨¡

- æ„å»ºå…·æœ‰æ‰‹åŠ¨æƒé‡è®¾ç½®åŠŸèƒ½çš„ MLP äºŒåˆ†ç±»å™¨
- å¯è§†åŒ–æ¯ä¸ªç¥ç»å…ƒåœ¨è¾“å…¥ç©ºé—´ä¸­çš„å“åº”åŒºåŸŸï¼ˆéšè—å±‚æ¿€æ´»å›¾ï¼‰
- æœ€ç»ˆå‡†ç¡®ç‡è¾¾ **100%**

### 3. åºåˆ—å»ºæ¨¡ä¸ LSTM å­¦ä¹ èƒ½åŠ›

- ä½¿ç”¨è‡ªå®šä¹‰ anbnã€anbncn åºåˆ—ç”Ÿæˆå™¨å­¦ä¹ å­—ç¬¦è®¡æ•°æœºåˆ¶
- å¯è§†åŒ– RNN çš„éšè—çŠ¶æ€å˜åŒ–ä¸é¢„æµ‹è¾“å‡ºçƒ­åŠ›å›¾
- ä½¿ç”¨ LSTM æˆåŠŸå­¦ä¹  Reber Grammar çš„åµŒå¥—ç»“æ„ï¼Œè¡¨ç°ä¼˜äºæ™®é€š RNN

---

## ğŸ§° æŠ€æœ¯æ ˆ

- **æ¡†æ¶å·¥å…·**ï¼šPyTorch, NumPy, Matplotlib, argparse
- **æ¨¡å‹ç»“æ„**ï¼šSVM, MLP, CNN, RNN, LSTM
- **å¯è§†åŒ–æ–¹æ³•**ï¼šéšè—çŠ¶æ€è½¨è¿¹å›¾ã€æ¿€æ´»çƒ­å›¾ã€è¾“å‡ºåˆ†å¸ƒå›¾ç­‰

---

## ğŸ“ Project Structure

â”œâ”€â”€ NetLin / NetFull / NetConv # CNN/MLP models for KMNIST classification
â”œâ”€â”€ check.py / check_main.py # Manually weighted MLP + hidden unit visualization
â”œâ”€â”€ anbn.py # Sequence generator for structured grammar
â”œâ”€â”€ RNN + LSTM + visual outputs # Sequence modeling and interpretability tools
â”œâ”€â”€ plot/ # Visual outputs (activation maps, trajectories, etc.)
â”œâ”€â”€ hw1.pdf # Final report and analysis


---

## ğŸ§  Features and Results Overview

### 1. Image Classification (KMNIST)

- Three models: Linear (NetLin), MLP (NetFull), CNN (NetConv)
- Accuracy: **70% / 85% / 94%**
- Fully implemented with PyTorch using custom training loops

### 2. Visualizing MLP Decision Logic

- Designed a 2-layer MLP with manually configured weights
- Visualized activation regions of each hidden neuron in input space
- Achieved **100% binary classification accuracy**

### 3. Sequence Modeling and Grammar Learning

- Built sequence models to learn anbn and anbncn patterns with RNN
- Visualized hidden state dynamics and softmax prediction outputs
- Applied LSTM to learn Reber Grammar with accurate state transitions, outperforming plain RNNs

---

## ğŸ§° Tech Stack

- **Frameworks**: PyTorch, NumPy, Matplotlib, argparse
- **Models**: SVM, MLP, CNN, RNN, LSTM
- **Visualization**: Hidden state trajectories, activation heatmaps, output distributions

